{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data-x](http://oi64.tinypic.com/o858n4.jpg)\n",
    "\n",
    "\n",
    "# Intro to Deep Learning with Keras\n",
    "\n",
    "#### Author: Alexander Fred Ojala\n",
    "\n",
    "_____\n",
    "\n",
    "# Why Keras\n",
    "Modular, powerful and intuitive Deep Learning python library built on Theano\n",
    "and TensorFlow\n",
    "* Minimalist, user-friendly interface\n",
    "* CPUs and GPUs\n",
    "* Open-source, developed and maintained by a community of contributors, and\n",
    "publicly hosted on github\n",
    "* Extremely well documented, lots of working examples\n",
    "* Very shallow learning curve â€”> it is by far one of the best tools for both beginners and experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Suppress TensorFlow and Keras warnings for cleaner output\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras backend\n",
    "\n",
    "We want Keras to use Tensorflow as a backend. If the warning above does not say:\n",
    "\n",
    "<div class='alert alert-danger'>Using TensorFlow backend.</div>\n",
    "\n",
    "Then open up the keras configuration file located in:\n",
    "\n",
    "`$HOME/.keras/keras.json` \n",
    "\n",
    "(On Windows replace `$HOME` with `%USERPROFILE%`)\n",
    "\n",
    "and change the entries in the JSON file to:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"floatx\": \"float32\",\n",
    "    \"epsilon\": 1e-07,\n",
    "    \"backend\": \"tensorflow\",\n",
    "    \"image_data_format\": \"channels_last\"\n",
    "}\n",
    "```\n",
    "\n",
    "After that restart your Kernel and run the code again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Core data structure in Keras is a model\n",
    "# The model is an object in which we organize layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras \"Hello World\" on Iris\n",
    "\n",
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data['data']\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode y\n",
    "import pandas as pd\n",
    "\n",
    "y = pd.get_dummies(y).values\n",
    "y[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, test_size=0.4,\n",
    "                                                    random_state=1337,\n",
    "                                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4)\n",
      "(90, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Sequential model\n",
    "The simplest model in Keras is the Sequential model, a linear stack of layers.\n",
    "\n",
    "* Sequential: linear stack of layers\n",
    "* Graph: multi-input, multi-output, with arbitrary connections inside\n",
    "* Sequential allows us to build NNs like legos, by adding one layer on top of the other, swapping layers in and out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model initialization\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can import layer classes and stack layers (in an NN model for example), by using `.add()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying the input shape\n",
    "\n",
    "The model needs to know what input shape it should expect. For this reason, the first layer in a  Sequential model needs to receive information about its input shape. There are several possible ways to do this:\n",
    "\n",
    "* Pass an input_shape argument to the first layer. This is a shape tuple (a tuple of integers or None entries, where None indicates that any positive integer may be expected).\n",
    "* Some 2D layers, such as Dense, support the specification of their input shape via the argument  input_dim, and some 3D temporal layers support the arguments input_dim and input_length.\n",
    "\n",
    "\n",
    "* **The following snippets are strictly equivalent:**\n",
    "* model.add(Dense(32, input_shape=(784,)))\n",
    "* model.add(Dense(32, input_dim=784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model contruction (architecture build computational graph)\n",
    "from keras.layers import Dense\n",
    "\n",
    "model.add( Dense(units=64, activation='relu', input_shape=(4,) ))\n",
    "model.add( Dense(units=3, activation='softmax') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation phase, specify learning process\n",
    "\n",
    "Run `.compile()` on the model to specify learning process.\n",
    "\n",
    "Before training a model, you need to configure the learning process, which is done via the  compile method. It receives three arguments:\n",
    "\n",
    "* **An optimizer:** This could be the string identifier of an existing optimizer (such as rmsprop or adagrad), or an instance of the Optimizer class. See: optimizers.\n",
    "* **A loss function:** This is the objective that the model will try to minimize. It can be the string identifier of an existing loss function (such as categorical_crossentropy or mse), or it can be an objective function. See: losses.\n",
    "* **A list of metrics:** For any classification problem you will want to set this to metrics=['accuracy']. A metric could be the string identifier of an existing metric or a custom metric function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can also specify our own optimizer or loss function\n",
    "\n",
    "### Different optimizers and their trade-offs\n",
    "To read more about gradient descent optimizers, hyperparameters etc. This is a recommended reading: http://ruder.io/optimizing-gradient-descent/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# or with we can specify loss function\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = SGD(lr=0.001, momentum = 0.9, nesterov=True),\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Keras models are trained on Numpy arrays of input data and labels. For training a model, you will typically use the fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 1.4451 - acc: 0.2667\n",
      "Epoch 2/50\n",
      "90/90 [==============================] - 0s 81us/step - loss: 1.2092 - acc: 0.3556\n",
      "Epoch 3/50\n",
      "90/90 [==============================] - 0s 74us/step - loss: 1.0582 - acc: 0.2667\n",
      "Epoch 4/50\n",
      "90/90 [==============================] - 0s 75us/step - loss: 1.0200 - acc: 0.2556\n",
      "Epoch 5/50\n",
      "90/90 [==============================] - 0s 71us/step - loss: 1.0141 - acc: 0.3333\n",
      "Epoch 6/50\n",
      "90/90 [==============================] - 0s 81us/step - loss: 0.9949 - acc: 0.3444\n",
      "Epoch 7/50\n",
      "90/90 [==============================] - 0s 49us/step - loss: 0.9672 - acc: 0.2444\n",
      "Epoch 8/50\n",
      "90/90 [==============================] - 0s 64us/step - loss: 0.9361 - acc: 0.2111\n",
      "Epoch 9/50\n",
      "90/90 [==============================] - 0s 68us/step - loss: 0.9077 - acc: 0.2667\n",
      "Epoch 10/50\n",
      "90/90 [==============================] - 0s 54us/step - loss: 0.8829 - acc: 0.4778\n",
      "Epoch 11/50\n",
      "90/90 [==============================] - 0s 90us/step - loss: 0.8599 - acc: 0.4889\n",
      "Epoch 12/50\n",
      "90/90 [==============================] - 0s 135us/step - loss: 0.8479 - acc: 0.5667\n",
      "Epoch 13/50\n",
      "90/90 [==============================] - 0s 120us/step - loss: 0.8301 - acc: 0.5667\n",
      "Epoch 14/50\n",
      "90/90 [==============================] - 0s 119us/step - loss: 0.8193 - acc: 0.5778\n",
      "Epoch 15/50\n",
      "90/90 [==============================] - 0s 122us/step - loss: 0.8038 - acc: 0.6000\n",
      "Epoch 16/50\n",
      "90/90 [==============================] - 0s 74us/step - loss: 0.7886 - acc: 0.6222\n",
      "Epoch 17/50\n",
      "90/90 [==============================] - 0s 71us/step - loss: 0.7742 - acc: 0.6000\n",
      "Epoch 18/50\n",
      "90/90 [==============================] - 0s 92us/step - loss: 0.7613 - acc: 0.6222\n",
      "Epoch 19/50\n",
      "90/90 [==============================] - 0s 110us/step - loss: 0.7509 - acc: 0.6111\n",
      "Epoch 20/50\n",
      "90/90 [==============================] - 0s 65us/step - loss: 0.7377 - acc: 0.6333\n",
      "Epoch 21/50\n",
      "90/90 [==============================] - 0s 72us/step - loss: 0.7256 - acc: 0.6667\n",
      "Epoch 22/50\n",
      "90/90 [==============================] - 0s 62us/step - loss: 0.7135 - acc: 0.7667\n",
      "Epoch 23/50\n",
      "90/90 [==============================] - 0s 73us/step - loss: 0.7028 - acc: 0.7444\n",
      "Epoch 24/50\n",
      "90/90 [==============================] - 0s 58us/step - loss: 0.6891 - acc: 0.7778\n",
      "Epoch 25/50\n",
      "90/90 [==============================] - 0s 65us/step - loss: 0.6806 - acc: 0.7556\n",
      "Epoch 26/50\n",
      "90/90 [==============================] - 0s 69us/step - loss: 0.6712 - acc: 0.7667\n",
      "Epoch 27/50\n",
      "90/90 [==============================] - 0s 86us/step - loss: 0.6626 - acc: 0.8111\n",
      "Epoch 28/50\n",
      "90/90 [==============================] - 0s 59us/step - loss: 0.6548 - acc: 0.8111\n",
      "Epoch 29/50\n",
      "90/90 [==============================] - 0s 137us/step - loss: 0.6495 - acc: 0.8111\n",
      "Epoch 30/50\n",
      "90/90 [==============================] - 0s 105us/step - loss: 0.6411 - acc: 0.8778\n",
      "Epoch 31/50\n",
      "90/90 [==============================] - 0s 53us/step - loss: 0.6325 - acc: 0.9000\n",
      "Epoch 32/50\n",
      "90/90 [==============================] - 0s 91us/step - loss: 0.6262 - acc: 0.8222\n",
      "Epoch 33/50\n",
      "90/90 [==============================] - 0s 85us/step - loss: 0.6192 - acc: 0.8222\n",
      "Epoch 34/50\n",
      "90/90 [==============================] - 0s 82us/step - loss: 0.6126 - acc: 0.8222\n",
      "Epoch 35/50\n",
      "90/90 [==============================] - 0s 102us/step - loss: 0.6076 - acc: 0.8222\n",
      "Epoch 36/50\n",
      "90/90 [==============================] - 0s 62us/step - loss: 0.6018 - acc: 0.8333\n",
      "Epoch 37/50\n",
      "90/90 [==============================] - 0s 90us/step - loss: 0.5971 - acc: 0.9222\n",
      "Epoch 38/50\n",
      "90/90 [==============================] - 0s 74us/step - loss: 0.5930 - acc: 0.9111\n",
      "Epoch 39/50\n",
      "90/90 [==============================] - 0s 127us/step - loss: 0.5857 - acc: 0.8667\n",
      "Epoch 40/50\n",
      "90/90 [==============================] - 0s 76us/step - loss: 0.5787 - acc: 0.8556\n",
      "Epoch 41/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.5961 - acc: 0.875 - 0s 90us/step - loss: 0.5734 - acc: 0.8444\n",
      "Epoch 42/50\n",
      "90/90 [==============================] - 0s 91us/step - loss: 0.5685 - acc: 0.8444\n",
      "Epoch 43/50\n",
      "90/90 [==============================] - 0s 136us/step - loss: 0.5645 - acc: 0.9111\n",
      "Epoch 44/50\n",
      "90/90 [==============================] - 0s 80us/step - loss: 0.5583 - acc: 0.9111\n",
      "Epoch 45/50\n",
      "90/90 [==============================] - 0s 91us/step - loss: 0.5544 - acc: 0.8889\n",
      "Epoch 46/50\n",
      "90/90 [==============================] - 0s 88us/step - loss: 0.5507 - acc: 0.9222\n",
      "Epoch 47/50\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.5296 - acc: 0.875 - 0s 114us/step - loss: 0.5449 - acc: 0.9333\n",
      "Epoch 48/50\n",
      "90/90 [==============================] - 0s 109us/step - loss: 0.5407 - acc: 0.9111\n",
      "Epoch 49/50\n",
      "90/90 [==============================] - 0s 67us/step - loss: 0.5361 - acc: 0.9000\n",
      "Epoch 50/50\n",
      "90/90 [==============================] - 0s 75us/step - loss: 0.5326 - acc: 0.8667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6fd3ce9668>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model by iterating over the training data in batches\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 50, batch_size= 32)\n",
    "\n",
    "# (convention that batch size is 2^X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "60/60 [==============================] - 0s 280us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.91666668653488159"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy on test set, only 120 \n",
    "model.evaluate(X_test, y_test, batch_size=128)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# computes loss and whatever metrics we have defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predictions on new data:\n",
    "\n",
    "class_probabilities = model.predict(X_test, batch_size=128)\n",
    "\n",
    "# gives output of the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09560332,  0.47244561,  0.43195114],\n",
       "       [ 0.79897875,  0.15575165,  0.04526962],\n",
       "       [ 0.02195202,  0.36864218,  0.60940582],\n",
       "       [ 0.73631465,  0.19597591,  0.06770945],\n",
       "       [ 0.0131119 ,  0.34098431,  0.64590377]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_probabilities[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras DNN on MNIST\n",
    "\n",
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "img_dim = 28*28\n",
    "num_classes = 10\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_dim)\n",
    "X_test = X_test.reshape(X_test.shape[0], 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sequential model to stack layers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model contruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize model constructor\n",
    "model = Sequential()\n",
    "# Add layers sequentially\n",
    "\n",
    "model.add(Dense(300, activation=tf.nn.leaky_relu, input_shape=(784,) ) )\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "# Second..\n",
    "model.add(Dense(200, activation=tf.nn.leaky_relu))\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "model.add(Dense(100, activation=tf.nn.leaky_relu))\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 316,810\n",
      "Trainable params: 316,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For a multi-class classification problem\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(learning_rate=0.1),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For a multi-class classification problem\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.2972 - acc: 0.9113\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.1315 - acc: 0.9601\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.0999 - acc: 0.9686\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.0793 - acc: 0.9746 1s - loss: \n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0684 - acc: 0.9776 0s - loss: 0.0686 - acc: 0.\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0596 - acc: 0.9809\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.0536 - acc: 0.9829\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.0507 - acc: 0.9835\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=8, batch_size=128,\n",
    "                   verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0730248921697\n",
      "Test accuracy: 0.9779\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xt81PWd7/HXh4RLICSAgXAJchEU\nwqXaUKxtVeIVbFdbKl3tSo89a+meXXranm23ursPt8tZH9hdd1tW3UvXelrbullF67pdLloM1dZL\ngaqQcBdRQhJukVwIkNvn/DG/0DEmmSG3md/M+/l4zIOZ+X1/83vPAO/88p3fzM/cHRERSQ+DEh1A\nREQGjkpfRCSNqPRFRNKISl9EJI2o9EVE0ohKX0Qkjaj0RQaQmZWb2aIEbv9CM2sws4xEZZDEMh2n\nL5IYZvZtYIa739GP2zgI3OXuv+ivbUi4aE9fkp5FhOrf6kBkNrPM/nx8SU2h+o8kiWNmd5vZW2ZW\nb2Y7zewzHZZ/ycx2RS3/cHD/ZDN72syOmdkJM3souP/bZvaTqPWnmpm3F5mZbTaz+8zs10AjMN3M\nvhi1jQNm9uUOGW4xszfMrC7IutjMlpnZtg7j/tTMnunieW42s9Vm9hszqzWz/zSzMVHLP2pmL5vZ\nSTN7M3qqprPMnTz+QTO7zswWA38O/H4w3fJmsDzXzH5gZlVmdtjM/qZ9KsbM7jSzX5vZd82sBvi2\nmV1kZi8Er+1xM/upmY0Kxv8YuBD4r2Abf9bJ6zzRzJ41sxoz229mX4rK+m0ze8LMHgte83IzW9DZ\n6yYh4u666BLzAiwDJhLZUfh94BQwIWrZYeAjgAEzgClABvAm8F1gBDAM+ESwzreBn0Q9/lTAgczg\n9mbgXWAOkAkMBj4JXBRs42oixfrhYPxCoBa4Psg4CZgFDAVqgNlR23od+GwXz3Nz8FzmBpmfas8Z\nPOYJ4KZgG9cHt8d2lbmTxz8IXNfZaxDc9wzwr8G2xwG/Ab4cLLsTaAG+Ejx+VvBaXx88z7HAi8D3\nOtteF6/zL4F/Cv5uLgWOAddG5TsTPN8MYDXwaqL/LerSy//LiQ6gSzgvwBvALcH1jcBXOxlzRVAi\nmZ0si6f0V8XI8Ez7doOi/G4X4/4ZuC+4Pgd4DxjaxdjNwP1RtwuBpqD0vgX8uMP4jcD/OI/MXZY+\nkA+cBbKi7rsdKA2u3wm8G+PxPw283tn2Or7OwGSgFRgZtXw18MOofL/o8FqcTvS/PV16d9H0jsTF\nzL4QTJ2cNLOTRPaE84LFk4G3OlltMvCOu7f0cLOHOmRYYmavBlMRJ4nsgcbKAPAj4PNmZsBy4Al3\nPxvndt8h8ltGHpHfXpa1vwZBhk8AE7rKfJ6mBNuqinr8fyWyx9/p45vZODMrCaaC6oCf8LvXJJaJ\nQI2710fd9w6R32jaVUddbwSG6b2EcNNfnsRkZlOAfwOuBV5x91Yze4PINAtEiuiiTlY9BFxoZpmd\nFP8pYHjU7fGdrH/u0DIzG0pkquULwH+6e3MwLx8rA+7+qpk1AVcCnw8u3Zkcdf1CoBk4Hmzjx+7+\npU7X6pA5Dh3HHiKyp5/XzQ/KjuusDu6b7+4nzOzTwENx5qkExpjZyKjiv5DI9JakKO3pSzxGECmP\nYwBm9kUie/rtHgG+YWZFwVErM4IfFL8BqoD7zWyEmQ0zs48H67wBXGWR48ZzgXtiZBhCZN76GNBi\nZkuAG6KW/wD4oplda2aDzGySmc2KWv4YkTJscfdfxdjWHWZWaGbDgVXAWndvJbIX/XtmdqOZZQTP\nZ5GZFcR4vK4cAaZacJSPu1cBzwF/b2Y5wfO4yMyu7uYxRgINwEkzmwR8s5NtfOAN5WB7h4CXgdXB\nc5kP/CHw0x4+HwkBlb7E5O47gb8HXiFSIvOAX0ctfxK4D3gcqCcy1z4mKMrfI/Jm47tABZE3gXH3\n54H/ALYD24Cfx8hQD/xv4Akic/KfB56NWv4b4ItE3jSuJfIG5ZSoh/gxkR9UP47jKf8Y+CGRqY1h\nwXbbS/IWIkfdHCOyZ/5Nev7/6MngzxNm9tvg+heI/IDbSeR5ruX900cd/TXwYSLP+b+BpzssXw38\nZTBd9I1O1r+dyDx/JfAz4K+CvxtJUfpwlqQFM8sCjhI52mdfN+M2E3lz9ZGByiYykLSnL+nifwFb\nuit8kXSgN3Il5VnkqwiMyOGMImlN0zsiImlE0zsiImkk6aZ38vLyfOrUqT1e/9SpU4wYMaLvAvWj\nMGWFcOUNU1YIV94wZYVw5e1N1m3bth1397ExByb6I8EdL0VFRd4bpaWlvVp/IIUpq3u48oYpq3u4\n8oYpq3u48vYmK7DV9TUMIiISTaUvIpJGVPoiImlEpS8ikkZU+iIiaUSlLyKSRlT6IiJpJOk+nCUi\nkgrcnTPNbZxubqWxqYUzza2cbmqjsamF082tnG5qDZa1cib4s6aymUX9nEulLyJpqaW1jcbmVs5E\nle+5Mm5qPbcsUtJtnA7Kun1ce1GfjlovusBPN7eed6YZo/p/8kWlLyKh19bmHK0/S8V7jVS8d/rc\nn5W1Z6g8eprvvPlSUMYt50q6ufX8vmzSDLIGZ0QuQ97/55gRQxg+OoNhgzMYfm5ZJlnvu51x7vaw\nIR+8P2twBr966cV+eoV+R6UvIkmvtc05Wn/mXKEffu90cD24ffL0B0o8L3sok0YNY2gGTBiV9f6S\njS7gTos5k6whg95X3EMzB2FmXSQMD5W+iCRcx1KvqAkK/WSwx95FqReMzmLupFwWz51Aweis4DKc\nSaOyyBqSAcDmzZtZtGhBIp5WUlLpi0i/60mpjx0ZKfX5BaO4ad6Ec4VeMDqLSaOyGDY4I0HPJtxU\n+iLSa61tzpG6M++bT//dn5FSb2lTqScDlb6IxOVsSyt7quv59eFmtm/aF7PUxwWlfunkUXxq/oTI\ntEswBaNST5y4St/MFgNrgAzgEXe/v8PyKcCjwFigBrjD3SuCZX8LfJLIB8GeB74afPeziCSpltY2\n9h1tYHvFSbZX1LK9opbd1XW/m4LZsbfTUm+fV5+oUk9aMUvfzDKAh4HrgQpgi5k96+47o4Y9ADzm\n7j8ys2uA1cByM/sY8HFgfjDuV8DVwOa+ewoi0httbc6B4w3nyn17xUl2VtVxprkNgJHDMplfkMsf\nfmI68wtyqX1nF5+58WqVekjFs6e/ENjv7gcAzKwEuAWILv1C4OvB9VLgmeC6A8OAIYABg4EjvY8t\nIj3h7rxb03iu3LdX1FJeWUfD2RYAhg/JYO7EXP7g8inML8hlfsEopowZzqBBvztUcfOJPSr8ELNY\nMy1mdiuw2N3vCm4vBy5395VRYx4HXnP3NWa2FHgKyHP3E2b2AHAXkdJ/yN3/opNtrABWAOTn5xeV\nlJT0+Ak1NDSQnZ3d4/UHUpiyQrjyhikr9E9ed6fmjHOwro23a9t4u7aVg3VtnGqOLM8cBBeOHMS0\n3OCSk8GEbGNQjGPR9dr2n95kLS4u3ubuMY9NjWdPv7N/AR1/UnwDeMjM7gReBA4DLWY2A5gNFATj\nnjezq9z9fR87c/fvA98HWLBggS9atCiOWJ2LHJPb8/UHUpiyQrjyhikr9E3eY/Vnz+297zgcmao5\n3nAWgMxBxiXjR3LzZaOYX5DLvEm5XDJ+JIMzzv9j/+n42g6UgcgaT+lXAJOjbhcAldED3L0SWApg\nZtnAZ929NtiDf9XdG4Jl64GPEvnBICI9dLKxKarcI0VfVXsGgEEGM8Zls+iSseemaGaNH6kpGQHi\nK/0twEwzm0ZkD/424PPRA8wsD6hx9zbgHiJH8gC8C3zJzFYT+Y3hauB7fZRdJC3Un2mm7HAdOw6f\n5M2KWnZU1PJuTeO55dPzRrBw2hjmTcrlQ5NHUTghhxFDdTS2dC7mvwx3bzGzlcBGIodsPuru5Wa2\nCtjq7s8Ci4DVZuZE9uL/JFh9LXANsIPIlNAGd/+vvn8aIqnhdFMrO6tq33ckzYHjp2h/6y3yYaZc\nPn/5hcyflMucSbnkZg1ObGgJlbh2B9x9HbCuw333Rl1fS6TgO67XCny5lxlFUlJjUwu7q+spr6zj\nuR1nuf+NF9l3tIHW4ENO+TlDmV8wik9fOol5wTTNmBFDEpxawk6/A4oMgOMNZymvrGNnZR07q+oo\nr6zl7ag9+JGDoWj6MG4ozGd+wSjmFeSSnzMssaElJan0RfpQW5vzTk1jUO6154r+aP3Zc2MKRmdR\nOCGHmz80kTkTcymcmMPe11+luHhhApNLulDpi/TQmeZW9h1peF+576qq41RT5IxJmYOMGeOy+cTM\nvEi5T8ihcEIOucM/OAe/LwW+p13CQaUvEoeTjU3srAqmZ4Ipmv1HG859yVj20ExmTxjJsgWTI+U+\nMYeZ+dkMzdRhkpJcVPoiUdydwydPv2/+fWdlHYdPnj43Jj9nKHMm5nLd7HwKJ+YwZ2IOk0e//6sK\nRJKVSl/SVnNrG/uPNrzvzdWdlXXUnYl8D80gg+ljsymaMprlV0xhzsQcZk/IIS97aIKTi/ScSl/S\nQv2ZZnZX17OzMij3qjr2VjfQ1Br5Jslhgwcxa3wOn/rQROZMjMy9zxqfc+6UeyKpQqUvKafuTDNv\nHmuh7IV956ZnDp743SdYx4wYwpyJOXzxE1MpnBCZnpmWl02GpmckDaj0JSW0tTmvHDjBE1sPsaGs\nmrMtbcBeplwwnDkTc7i1qCCYf89l3MihmI6WkTSl0pdQO1TTyJPbKnhqWwWHT54mZ1gmn1swmUlt\nR/iDm65i5DB9RYFINJW+hM7pplY2lFfxxJYKXjlwAjP4xIw8vrVkFjcU5jNscAabNx9X4Yt0QqUv\noeDuvH7oJE9ureDnb1ZSf7aFC8cM50+vv5ilRQVMGpWV6IgioaDSl6R2tP4MP/vtYZ7cVsH+ow1k\nDc5gybzxfG7BZBZOHaNj40XOk0pfkk5TSxsv7D7K2m2HKN1zjNY2p2jKaL7z2XncNG+Cpm1EekGl\nL0ljd3UdT26t4JnXD3PiVBPjRg7lS1dOZ9mCAi4aG45znIokO5W+JFRtYzPPbq/kya2H2F5Ry+AM\n47rZ+SxbUMBVM8eS2YNzuIpI11T6MuBa25yX3zrOE1sr2FheTVNLG7PGj+TeTxXy6csm6UQhIv1I\npS8D5t0Tjazddoi12yqorD1DbtZgbv/IZJYtmMyciTn6wJTIAIir9M1sMbCGyDlyH3H3+zssn0Lk\nZOhjgRrgDnevMLNi4LtRQ2cBt7n7M30RXpJfY1ML63dU8+S2Q7x6oAYzuHLmWP78k7O5bnbkmHoR\nGTgxS9/MMoCHgeuBCmCLmT3r7jujhj0APObuPzKza4DVwHJ3LwUuDR5nDLAfeK6Pn4MkGXfnt++e\n5Mmth/j59ioazrYw5YLhfOOGi1n64QIm6ph6kYSJZ09/IbDf3Q8AmFkJcAsQXfqFwNeD66VAZ3vy\ntwLr3b2xk2WSAo7WneGp3x7myW2HOHDsFFmDM/jk/AksKypg4bQxmr4RSQLm7Wdm7mqA2a3AYne/\nK7i9HLjc3VdGjXkceM3d15jZUuApIM/dT0SNeQH4B3f/eSfbWAGsAMjPzy8qKSnp8RNqaGggOzsc\nh/eFKSt0nrelzXnjaCsvHW5hx/FW2hxmjhrElQWZfGR8JlmZiSn6VHhtk1WYskK48vYma3Fx8TZ3\nXxBrXDx7+p39r+34k+IbwENmdifwInAYaDn3AGYTgHnAxs424O7fB74PsGDBAl+0aFEcsTq3efNm\nerP+QApTVnh/3l1VwTH1bxym5lQT+TlD+aOrp3JrUQHTk+CY+jC/tskuTFkhXHkHIms8pV8BTI66\nXQBURg9w90pgKYCZZQOfdffaqCGfA37m7s29iyuJ1NDkPPbKQZ7Yeoiyw3UMzjCuL8xn2YLJXDkj\nT8fUi4RAPKW/BZhpZtOI7MHfBnw+eoCZ5QE17t4G3EPkSJ5otwf3SwjtP1rPP27az7rtjbR4OYUT\ncvir3yvklkt1TL1I2MQsfXdvMbOVRKZmMoBH3b3czFYBW939WWARsNrMnMj0zp+0r29mU4n8pvDL\nPk8v/aqq9jTfe34fT247xPAhmSyanMnXbvkocyflJjqaiPRQXMfpu/s6YF2H++6Nur4WWNvFugeB\nST2PKAPtZGMT/7z5LX748kHc4c6PTWPlNTPYvuVlFb5IyOkTuXLOmeZWfvjyQf6pdD/1Z1v4zGWT\n+Pp1FzN5zPBERxORPqLSF1pa21i7rYLv/WIf1XVnuGbWOL554yXMnpCT6Ggi0sdU+mnM3dlYfoS/\n27ibt46d4rILR7Hmtku5fPoFiY4mIv1EpZ+mXjtwgvs37Ob1d09y0dgR/MsdRdw4J1+fmhVJcSr9\nNLOrqo6/3bCb0j3HGJ8zjPuXzuPWogIdYy+SJlT6aaLivUb+4fm9/Oz1w4wcmsndS2Zx58em6lsu\nRdKMSj/F1Zxq4uHS/fz4lXfAYMVV0/njq2eQO1znmRVJRyr9FNXY1MIPXnqb7794gFNNLdxaVMDX\nrrtYX2sskuZU+immubWNki2H+MdN+zhWf5YbCvP55o2XMDN/ZKKjiUgSUOmniLY2Z11ZFQ9s3MPB\nE40snDqGf7njwxRNGZPoaCKSRFT6KeDX+49z//rd7DhcyyX5I3n0zgUUXzJOh1+KyAeo9EOs7HAt\n39mwm5f2HWfSqCweWPYhPnPZJDIGqexFpHMq/RB658QpHnhuL//1ZiWjhg/mLz85mzs+OkWHX4pI\nTCr9EDlWf5YHX9jH46+9S2aGsbJ4Biuunk7OMB1+KSLxUemHQP2ZZv7tpbd55KUDnG1p47aPTOar\n185kXM6wREcTkZBR6Sexsy2tPP7auzz4wn5qTjXxyXkT+NMbLk6Kc9CKSDip9JNQW5vzn28e5u+f\n20vFe6e5YvoF3L1kFh+aPCrR0UQk5FT6ScTd+eXeY3xnwx52VdVROCGHH/3PeVw1M0+HX4pIn4ir\n9M1sMbCGyDlyH3H3+zssn0LkZOhjgRrgDnevCJZdCDxC5Dy5DtwUnEJRorxx6CT3r9/FqwdqmDwm\nizW3XcrvzZ/IIB1+KSJ9KGbpm1kG8DBwPVABbDGzZ919Z9SwB4DH3P1HZnYNsBpYHix7DLjP3Z83\ns2ygrU+fQci9dayBBzbuYX1ZNReMGMJf3zyH2xdeyJBMfdWxiPS9ePb0FwL73f0AgJmVALcA0aVf\nCHw9uF4KPBOMLQQy3f15AHdv6KPcoVdzqokflp3lpedeZFjmIL523UzuunI62UM14yYi/SeehpkE\nHIq6XQFc3mHMm8BniUwBfQYYaWYXABcDJ83saWAa8Avgbndv7W3wsPv2s+W8dLiF5VdMZeU1M8jL\nHproSCKSBszdux9gtgy40d3vCm4vBxa6+1eixkwEHiJS7C8S+QEwh8iU0A+Ay4B3gf8A1rn7Dzps\nYwWwAiA/P7+opKSkx0+ooaGB7OzkPqSxqdX5yguNLBjrfOnS5M4aLQyvbbswZYVw5Q1TVghX3t5k\nLS4u3ubuC2IOdPduL8AVwMao2/cA93QzPhuoCK5/FNgctWw58HB32ysqKvLeKC0t7dX6A2FjWZVP\n+dbP/cEnf5HoKOclDK9tuzBldQ9X3jBldQ9X3t5kBbZ6jD53d+J5t3ALMNPMppnZEOA24NnoAWaW\nZ2btj3UPkSN52tcdbWZjg9vX8P73AtLS+rJqRg0fzKwxerNWRAZWzNZx9xZgJbAR2AU84e7lZrbK\nzG4Ohi0C9pjZXiAfuC9YtxX4BrDJzHYABvxbnz+LEDnb0sovdh3h+tn5ZOpwTBEZYHEdKuLu64B1\nHe67N+r6WmBtF+s+D8zvRcaU8vL+E9SfaWHJvPFQ/V6i44hImtH8wgBbX1bFyKGZfHxGXqKjiEga\nUukPoObWNp7beYRrZ49jaKa++15EBp5KfwC9dqCGk43NLJk3IdFRRCRNqfQH0PqyKoYPyeDqi8fG\nHiwi0g9U+gOktc3ZWF5N8SXjdFpDEUkYlf4A2XqwhuMNTZGjdkREEkSlP0DWl1UzNHMQxZeMS3QU\nEUljKv0B0NbmbCir5uqLxzJC36IpIgmk0h8Ab1ScpLrujKZ2RCThVPoDYP2OKgZnGNfMyk90FBFJ\ncyr9fuburC+r5hMz8sjNGpzoOCKS5lT6/ay8so6K906zZK4+kCUiiafS72frdlSRMci4vlBTOyKS\neCr9ftQ+tXPF9AsYPWJIouOIiKj0+9OeI/W8ffwUi+fqqB0RSQ4q/X60fkc1ZnDjHJW+iCQHlX4/\n2lBWzUemjmHsyKGJjiIiAqj0+81bxxrYc6SemzS1IyJJRKXfTzaUVQOwWIdqikgSiav0zWyxme0x\ns/1mdncny6eY2SYz225mm82sIGpZq5m9EVye7cvwyWzdjiouu3AU43OHJTqKiMg5MUvfzDKAh4El\nQCFwu5kVdhj2APCYu88HVgGro5addvdLg8vNfZQ7qb17opHyyjpu0l6+iCSZePb0FwL73f2AuzcB\nJcAtHcYUApuC66WdLE8rG8qrAHSopogkHXP37geY3Qosdve7gtvLgcvdfWXUmMeB19x9jZktBZ4C\n8tz9hJm1AG8ALcD97v5MJ9tYAawAyM/PLyopKenxE2poaCA7O7vH6/eFVa+cps3h2x/L6nZcMmQ9\nH2HKG6asEK68YcoK4crbm6zFxcXb3H1BzIHu3u0FWAY8EnV7OfBghzETgaeB14E1QAWQ274s+HM6\ncBC4qLvtFRUVeW+Ulpb2av3eOvxeo0/51s/9oRf2xRyb6KznK0x5w5TVPVx5w5TVPVx5e5MV2Oox\n+tzdieeMHhXA5KjbBUBlhx8clcBSADPLBj7r7rVRy3D3A2a2GbgMeCuO7YZS+1E7SzS1IyJJKJ45\n/S3ATDObZmZDgNuA9x2FY2Z5Ztb+WPcAjwb3jzazoe1jgI8DO/sqfDLaUFbNrPEjmT42HL9Oikh6\niVn67t4CrAQ2AruAJ9y93MxWmVn70TiLgD1mthfIB+4L7p8NbDWzN4m8wXu/u6ds6R+tP8OWd2r0\nBq6IJK24Ttjq7uuAdR3uuzfq+lpgbSfrvQzM62XG0NhYfgR3uGmeDtUUkeSkT+T2oQ1lVUwfO4KZ\n4zS1IyLJSaXfR2pONfHqgRqWzB2PmSU6johIp1T6feT5ndW0trlOiygiSU2l30fWl1UzeUwWcybm\nJDqKiEiXVPp9oPZ0M7/ef5yb5k7Q1I6IJDWVfh/YtOsIza2uQzVFJOmp9PvAuh3VTMgdxocKRiU6\niohIt1T6vdRwtoUX9x1j8dzxDBqkqR0RSW4q/V4q3X2UppY2HbUjIqGg0u+l9WVVjB05lKIpoxMd\nRUQkJpV+L5xuaqV09zFunJNPhqZ2RCQEVPq98Mu9Rznd3KqpHREJDZV+L6wvq2b08MFcPm1MoqOI\niMRFpd9DZ1ta2bTrKDcUjiczQy+jiISD2qqHfrXvOA1nW1gyTx/IEpHwUOn30PqyakYOy+RjF+Ul\nOoqISNxU+j3Q3NrG8zuPcP3sfIZk6iUUkfBQY/XAK2+doPZ0M0t0hiwRCZm4St/MFpvZHjPbb2Z3\nd7J8ipltMrPtZrbZzAo6LM8xs8Nm9lBfBU+k9WXVjBiSwZUzNbUjIuESs/TNLAN4GFgCFAK3m1lh\nh2EPAI+5+3xgFbC6w/L/C/yy93ETr7XNea68mmtm5zNscEai44iInJd49vQXAvvd/YC7NwElwC0d\nxhQCm4LrpdHLzawIyAee633cxPvN2zWcONXEEn2NsoiEkLl79wPMbgUWu/tdwe3lwOXuvjJqzOPA\na+6+xsyWAk8BecB7wAvAcuBaYEH0elHrrwBWAOTn5xeVlJT0+Ak1NDSQnd1/Jyb/8c6zvFTRwoPX\nDGdoZu++eqG/s/a1MOUNU1YIV94wZYVw5e1N1uLi4m3uviDmQHfv9gIsAx6Jur0ceLDDmInA08Dr\nwBqgAsgFVgJ/Foy5E3go1vaKioq8N0pLS3u1fndaW9v8I3/zvH/5sa198nj9mbU/hClvmLK6hytv\nmLK6hytvb7ICWz1Gv7o7mXH8AKkAJkfdLgAqO/zgqASWAphZNvBZd681syuAK83sj4FsYIiZNbj7\nB94MDoPXD73H0fqz+kCWiIRWPKW/BZhpZtOAw8BtwOejB5hZHlDj7m3APcCjAO7+B1Fj7iQyvRPK\nwofIGbKGZAzimlnjEh1FRKRHYr6R6+4tRKZpNgK7gCfcvdzMVpnZzcGwRcAeM9tL5E3b+/opb8K4\nOxvKqrlyZh4jhw1OdBwRkR6JZ08fd18HrOtw371R19cCa2M8xg+BH553wiSxvaKWwydP87XrZiY6\niohIj+kTuXFaX1ZN5iDj+sL8REcREekxlX4cIlM7VVxx0QWMGj4k0XFERHpMpR+HXVX1HDzRyE36\nrh0RCTmVfhw2lFUxyOAGTe2ISMip9OOwrqyahdPGcEH20ERHERHpFZV+DPuP1rP/aIOmdkQkJaj0\nY1i/oxqAG+foU7giEn4q/RjWlVWzYMpo8nOGJTqKiEivqfS7cfD4KXZV1bFYX6MsIilCpd+N9WWR\nqR2VvoikCpV+NzaUVfGhglwKRg9PdBQRkT6h0u9CxXuNvFlRy+K5OmpHRFKHSr8LG4KpHZ0WUURS\niUq/CxvKqpk9IYepeSMSHUVEpM+o9DtxpO4MW995T3v5IpJyVPqd2Fgemdq5SadFFJEUo9LvxPod\n1cwYl82McSMTHUVEpE+p9Ds40XCW194+wU2a2hGRFKTS7+C5nUdoc3SopoikpLhK38wWm9keM9tv\nZnd3snyKmW0ys+1mttnMCqLu32Zmb5hZuZn9UV8/gb62bkcVUy4YzuwJmtoRkdQTs/TNLAN4GFgC\nFAK3m1lhh2EPAI+5+3xgFbA6uL8K+Ji7XwpcDtxtZhP7Knxfq21s5pW3TrBk7gTMLNFxRET6XDx7\n+guB/e5+wN2bgBLglg5jCoFNwfXS9uXu3uTuZ4P7h8a5vYR5ftcRWtpch2qKSMoyd+9+gNmtwGJ3\nvyu4vRy43N1XRo15HHjN3deY2VLgKSDP3U+Y2WTgv4EZwDfd/eFOtrECWAGQn59fVFJS0uMn1NDQ\nQHZ2do/W/e62M1TUt/HA1VnvDUiBAAALw0lEQVQDsqffm6yJEKa8YcoK4cobpqwQrry9yVpcXLzN\n3RfEHOju3V6AZcAjUbeXAw92GDMReBp4HVgDVAC5nYz5DZDf3faKioq8N0pLS3u0Xt3pJp/55+t8\n1X+V92r756OnWRMlTHnDlNU9XHnDlNU9XHl7kxXY6jH63N3jmm6pACZH3S4AKjv84Kh096Xufhnw\nF8F9tR3HAOXAlXFsc8C9sPsoTa1tmtoRkZQWT+lvAWaa2TQzGwLcBjwbPcDM8sys/bHuAR4N7i8w\ns6zg+mjg48Cevgrfl9bvqGbcyKF8+MLRiY4iItJvYpa+u7cAK4GNwC7gCXcvN7NVZnZzMGwRsMfM\n9gL5wH3B/bOB18zsTeCXwAPuvqOPn0OvNTa1sHnvURbPHc+gQTpqR0RSV2Y8g9x9HbCuw333Rl1f\nC6ztZL3ngfm9zNjvNu85xpnmNpboA1kikuKS+hDKgbK+rJoLRgxh4bQxiY4iItKv0r70zzS38sKu\nI9wwJ58MTe2ISIpL+9J/ad9xTjW1ampHRNJC2pf++rIqcrMGc8VFFyQ6iohIv0vr0m9qaeP5nUe4\nvjCfwRlp/VKISJpI66Z7+a3j1J9p0QeyRCRtpHXpr99RTfbQTD4xMy/RUUREBkTaln5LaxvP7azm\n2tnjGJqZkeg4IiIDIm1L/zdv1/BeY7OmdkQkraRt6a8rqyJrcAZXXzwu0VFERAZMWpZ+a5uzsfwI\nxbPGkjVEUzsikj7SsvS3vfMex+rP6uTnIpJ20rL015dVMSRzENfM0tSOiKSXtCv9tjZnQ1k1V80c\nS/bQuL5kVEQkZaRd6b9ZcZKq2jPcNE9H7YhI+km70t9QVs3gDOPa2fmJjiIiMuDSqvTdnXVlVXzs\nojxyswYnOo6IyIBLq9Ivr6zjUM1pTe2ISNqKq/TNbLGZ7TGz/WZ2dyfLp5jZJjPbbmabzawguP9S\nM3vFzMqDZb/f10/gfGwoqyZjkHF9oUpfRNJTzNI3swzgYWAJUAjcbmaFHYY9ADzm7vOBVcDq4P5G\n4AvuPgdYDHzPzEb1Vfjz0T6189HpYxgzYkgiIoiIJFw8e/oLgf3ufsDdm4AS4JYOYwqBTcH10vbl\n7r7X3fcF1yuBo8DYvgh+vvYdbeDAsVP6QJaIpDVz9+4HmN0KLHb3u4Lby4HL3X1l1JjHgdfcfY2Z\nLQWeAvLc/UTUmIXAj4A57t7WYRsrgBUA+fn5RSUlJT1+Qg0NDWRnZ3/g/mf2N/Gf+5v5bnEWo4Ym\nx1sZXWVNVmHKG6asEK68YcoK4crbm6zFxcXb3H1BzIHu3u0FWAY8EnV7OfBghzETgaeB14E1QAWQ\nG7V8ArAH+Gis7RUVFXlvlJaWdnr/jd/9pS/755d79dh9rausySpMecOU1T1cecOU1T1ceXuTFdjq\nMfrV3eOa3qkAJkfdLgAqO/zgqHT3pe5+GfAXwX21AGaWA/w38Jfu/moc2+tzB441sLu6nsX6GmUR\nSXPxlP4WYKaZTTOzIcBtwLPRA8wsz8zaH+se4NHg/iHAz4i8yftk38U+P+vLqgFU+iKS9mKWvru3\nACuBjcAu4Al3LzezVWZ2czBsEbDHzPYC+cB9wf2fA64C7jSzN4LLpX39JGLZUFbNpZNHMXFU1kBv\nWkQkqcT1jWPuvg5Y1+G+e6OurwXWdrLeT4Cf9DJjrxyqaWTH4VruWTIrkTFERJJCchzG0o82BFM7\nS3SopohI6pf++rIq5kzM4cILhic6iohIwqV06VfVnua3757kpnnayxcRgRQv/Y06akdE5H1SuvTX\nlVVzcX42F40Nx6fxRET6W8qW/rH6s2w5WKM3cEVEoqRs6T+3sxp3WKLvzhcROSdlS3/9jmqm543g\nkvyRiY4iIpI0UrL03zvVxCsHTrB47njMLNFxRESSRkqW/vM7j9Da5prPFxHpICVLf31ZFQWjs5g7\nKSfRUUREkkrKlX5js/Or/cdZoqkdEZEPSLnSf+NYK82tzhJ9CldE5ANSrvS3VrcwPmcYlxYk5Pzr\nIiJJLaVK/9TZFnYcb2Xx3PEMGqSpHRGRjlKq9Ev3HKW5DZbou3ZERDqVUqW/vqyanCGwYOqYREcR\nEUlKKVP6Z5pbKd19lKL8TDI0tSMi0qm4St/MFpvZHjPbb2Z3d7J8ipltMrPtZrbZzAqilm0ws5Nm\n9vO+DN5R3elmrp2dz+UT4joDpIhIWopZ+maWATwMLAEKgdvNrLDDsAeAx9x9PrAKWB217O+A5X0T\nt2vjcobx4O2XMWtMRn9vSkQktOLZ018I7Hf3A+7eBJQAt3QYUwhsCq6XRi93901AfR9kFRGRXjJ3\n736A2a3AYne/K7i9HLjc3VdGjXkceM3d15jZUuApIM/dTwTLFwHfcPdPdbGNFcAKgPz8/KKSkpIe\nP6GGhgays8Nx0pQwZYVw5Q1TVghX3jBlhXDl7U3W4uLibe6+IOZAd+/2AiwDHom6vRx4sMOYicDT\nwOvAGqACyI1avgj4eaxtuTtFRUXeG6Wlpb1afyCFKat7uPKGKat7uPKGKat7uPL2Jiuw1ePo2Hje\n9awAJkfdLgAqO/zgqASWAphZNvBZd6+N47FFRGQAxTOnvwWYaWbTzGwIcBvwbPQAM8szs/bHugd4\ntG9jiohIX4hZ+u7eAqwENgK7gCfcvdzMVpnZzcGwRcAeM9sL5AP3ta9vZi8BTwLXmlmFmd3Yx89B\nRETiFNdB7e6+DljX4b57o66vBdZ2se6VvQkoIiJ9J2U+kSsiIrHFPGRzoJnZMeCdXjxEHnC8j+L0\ntzBlhXDlDVNWCFfeMGWFcOXtTdYp7j421qCkK/3eMrOtHs+xqkkgTFkhXHnDlBXClTdMWSFceQci\nq6Z3RETSiEpfRCSNpGLpfz/RAc5DmLJCuPKGKSuEK2+YskK48vZ71pSb0xcRka6l4p6+iIh0QaUv\nIpJGUqb0Y53dK5mY2aNmdtTMyhKdJRYzm2xmpWa2y8zKzeyric7UHTMbZma/MbM3g7x/nehMsZhZ\nhpm93t9nl+sLZnbQzHaY2RtmtjXRebpjZqPMbK2Z7Q7+/V6R6ExdMbNLgte0/VJnZl/rl22lwpx+\ncHavvcD1RL4VdAtwu7vvTGiwLpjZVUADkbONzU10nu6Y2QRggrv/1sxGAtuATyfxa2vACHdvMLPB\nwK+Ar7r7qwmO1iUz+z/AAiDHuzjnRLIws4PAAndP+g87mdmPgJfc/ZHgyyKHu/vJROeKJeizw0TO\nW9KbD6p2KlX29OM5u1fScPcXgZpE54iHu1e5+2+D6/VEvnRvUmJTdS34avGG4Obg4JK0ezbB+aQ/\nCTyS6CypxMxygKuAHwC4e1MYCj9wLfBWfxQ+pE7pTwIORd2uIImLKazMbCpwGfBaYpN0L5gueQM4\nCjzv7smc93vAnwFtiQ4SJweeM7NtwRnvktV04Bjw/4Kps0fMbESiQ8XpNuDf++vBU6X0rZP7knbv\nLoyCk+M8BXzN3esSnac77t7q7pcSOeHPQjNLyik0M/sUcNTdtyU6y3n4uLt/GFgC/EkwVZmMMoEP\nA//s7pcBp4Ckfq8PIJiGupnI19H3i1Qp/Zhn95KeC+bGnwJ+6u5PJzpPvIJf5zcDixMcpSsfB24O\n5slLgGvM7CeJjdS94Cx5uPtR4GdEplaTUQVQEfVb3loiPwSS3RLgt+5+pL82kCqlH/PsXtIzwRuj\nPwB2ufs/JDpPLGY21sxGBdezgOuA3YlN1Tl3v8fdC9x9KpF/sy+4+x0JjtUlMxsRvJlPMFVyA5CU\nR6C5ezVwyMwuCe66FkjKgw86uJ1+nNqBOE+ikuzcvcXM2s/ulQE86u7lCY7VJTP7dyJnG8szswrg\nr9z9B4lN1aWPA8uBHcE8OcCfByfWSUYTgB8FR0AMInKmt6Q/FDIk8oGfRfYDyAQed/cNiY3Ura8A\nPw12BA8AX0xwnm6Z2XAiRyB+uV+3kwqHbIqISHxSZXpHRETioNIXEUkjKn0RkTSi0hcRSSMqfRGR\nNKLSFxFJIyp9EZE08v8BKFJArOSzmI4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6fb8bc69b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(8),history.history['acc'])\n",
    "plt.title('accuracy per iteration')\n",
    "plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Great accuracy for an ANN in so few training steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN in Keras\n",
    "## 99.5% accuracy on MNIST in 12 epochs\n",
    "\n",
    "Note this takes ~1hr to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "# notice that we don't flatten image\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "#normalize\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "11136/60000 [====>.........................] - ETA: 8:09 - loss: 0.1005 - acc: 0.9699"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
